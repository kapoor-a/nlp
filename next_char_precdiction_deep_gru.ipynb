{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOueQJP+Ai47qXfBcf9WXkK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kapoor-a/nlp/blob/main/next_char_precdiction_deep_gru.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GuPdbFRq4lEG",
        "outputId": "f2c820a2-b4af-4e2a-9451-b0487250993c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting trax\n",
            "  Downloading trax-1.4.1-py2.py3-none-any.whl (637 kB)\n",
            "\u001b[K     |████████████████████████████████| 637 kB 28.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from trax) (0.5.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from trax) (3.2.2)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.7/dist-packages (from trax) (0.25.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from trax) (1.3.0)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from trax) (4.6.0)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.7/dist-packages (from trax) (0.3.22+cuda11.cudnn805)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from trax) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from trax) (1.7.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from trax) (5.4.8)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from trax) (1.15.0)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.7/dist-packages (from trax) (0.3.23)\n",
            "Collecting funcsigs\n",
            "  Downloading funcsigs-1.0.2-py2.py3-none-any.whl (17 kB)\n",
            "Collecting tensorflow-text\n",
            "  Downloading tensorflow_text-2.10.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.9 MB 53.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.7/dist-packages (from gym->trax) (0.0.8)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.7/dist-packages (from gym->trax) (4.13.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym->trax) (1.5.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.0->gym->trax) (3.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.0->gym->trax) (4.1.1)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.7/dist-packages (from jax->trax) (3.3.0)\n",
            "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.7/dist-packages (from jax->trax) (0.8.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.7/dist-packages (from etils[epath]->jax->trax) (5.10.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->trax) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->trax) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->trax) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->trax) (1.4.4)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->trax) (2.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->trax) (2.23.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->trax) (0.10.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->trax) (0.3.6)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->trax) (1.10.0)\n",
            "Requirement already satisfied: protobuf>=3.12.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->trax) (3.17.3)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->trax) (2.0.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->trax) (4.64.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tensorflow-datasets->trax) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tensorflow-datasets->trax) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tensorflow-datasets->trax) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tensorflow-datasets->trax) (2.10)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-metadata->tensorflow-datasets->trax) (1.56.4)\n",
            "Requirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-text->trax) (0.12.0)\n",
            "Collecting tensorflow<2.11,>=2.10.0\n",
            "  Downloading tensorflow-2.10.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (578.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 578.0 MB 15 kB/s \n",
            "\u001b[?25hCollecting keras<2.11,>=2.10.0\n",
            "  Downloading keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 49.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text->trax) (0.2.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text->trax) (0.27.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text->trax) (3.1.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text->trax) (1.50.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text->trax) (1.14.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text->trax) (14.0.6)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text->trax) (1.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text->trax) (57.4.0)\n",
            "Collecting tensorboard<2.11,>=2.10\n",
            "  Downloading tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.9 MB 46.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text->trax) (0.4.0)\n",
            "Collecting flatbuffers>=2.0\n",
            "  Downloading flatbuffers-22.10.26-py2.py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text->trax) (21.3)\n",
            "Collecting tensorflow-estimator<2.11,>=2.10.0\n",
            "  Downloading tensorflow_estimator-2.10.0-py2.py3-none-any.whl (438 kB)\n",
            "\u001b[K     |████████████████████████████████| 438 kB 68.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text->trax) (1.6.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow<2.11,>=2.10.0->tensorflow-text->trax) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow<2.11,>=2.10.0->tensorflow-text->trax) (1.5.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text->trax) (1.35.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text->trax) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text->trax) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text->trax) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text->trax) (1.8.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text->trax) (0.6.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text->trax) (4.9)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text->trax) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text->trax) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text->trax) (1.3.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text->trax) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text->trax) (3.2.2)\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras, flatbuffers, tensorflow, tensorflow-text, funcsigs, trax\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.9.0\n",
            "    Uninstalling tensorflow-estimator-2.9.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.9.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.9.1\n",
            "    Uninstalling tensorboard-2.9.1:\n",
            "      Successfully uninstalled tensorboard-2.9.1\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.9.0\n",
            "    Uninstalling keras-2.9.0:\n",
            "      Successfully uninstalled keras-2.9.0\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 1.12\n",
            "    Uninstalling flatbuffers-1.12:\n",
            "      Successfully uninstalled flatbuffers-1.12\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.9.2\n",
            "    Uninstalling tensorflow-2.9.2:\n",
            "      Successfully uninstalled tensorflow-2.9.2\n",
            "Successfully installed flatbuffers-22.10.26 funcsigs-1.0.2 keras-2.10.0 tensorboard-2.10.1 tensorflow-2.10.0 tensorflow-estimator-2.10.0 tensorflow-text-2.10.0 trax-1.4.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk) (7.1.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk) (2022.6.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk) (4.64.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install trax\n",
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import gutenberg\n",
        "import nltk\n",
        "import random as rnd\n",
        "import numpy as np\n",
        "import trax.layers as tl\n",
        "import trax"
      ],
      "metadata": {
        "id": "a5lfJOF74oKY"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('gutenberg')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gr8FFJbJI5DV",
        "outputId": "d1011c1b-e961-4a1f-de21-e9e6212c4df0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/gutenberg.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_play(name):\n",
        "  play = gutenberg.raw(name).split(\"\\n\")\n",
        "  lines = []\n",
        "  for line in play:\n",
        "    line = line.strip().lower()\n",
        "    if line != \"\":\n",
        "      lines.append(line)\n",
        "  print(name, lines[0], len(lines))\n",
        "  return lines"
      ],
      "metadata": {
        "id": "T64DEJWS5UeN"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lines = []\n",
        "for f in gutenberg.fileids():\n",
        "  lines += get_play(f)\n",
        "  lines.append(\"/n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBc966VX6wVA",
        "outputId": "5fb383cb-0752-41ef-dbc6-c3b3332260c7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "austen-emma.txt [emma by jane austen 1816] 14283\n",
            "austen-persuasion.txt [persuasion by jane austen 1818] 7356\n",
            "austen-sense.txt [sense and sensibility by jane austen 1811] 12773\n",
            "bible-kjv.txt [the king james bible] 74645\n",
            "blake-poems.txt [poems by william blake 1789] 1094\n",
            "bryant-stories.txt [stories to tell to children by sara cone bryant 1918] 4123\n",
            "burgess-busterbrown.txt [the adventures of buster bear by thornton w. burgess 1920] 1315\n",
            "carroll-alice.txt [alice's adventures in wonderland by lewis carroll 1865] 2479\n",
            "chesterton-ball.txt [the ball and the cross by g.k. chesterton 1909] 7890\n",
            "chesterton-brown.txt [the wisdom of father brown by g. k. chesterton 1914] 6443\n",
            "chesterton-thursday.txt [the man who was thursday by g. k. chesterton 1908] 5475\n",
            "edgeworth-parents.txt [the parent's assistant, by maria edgeworth] 14492\n",
            "melville-moby_dick.txt [moby dick by herman melville 1851] 19651\n",
            "milton-paradise.txt [paradise lost by john milton 1667] 10572\n",
            "shakespeare-caesar.txt [the tragedie of julius caesar by william shakespeare 1599] 2774\n",
            "shakespeare-hamlet.txt [the tragedie of hamlet by william shakespeare 1599] 3966\n",
            "shakespeare-macbeth.txt [the tragedie of macbeth by william shakespeare 1603] 2588\n",
            "whitman-leaves.txt [leaves of grass by walt whitman 1855] 14169\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "split = int(0.95*len(lines))\n",
        "train = lines[:split]\n",
        "eval = lines[split:]"
      ],
      "metadata": {
        "id": "x-MK8VpV8Wo5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def line_to_tensor(line, EOS_int=1):\n",
        "    tensor = [ord(c) for c in line] \n",
        "    tensor.append(EOS_int)\n",
        "    return tensor"
      ],
      "metadata": {
        "id": "SPDYy6iaISMW"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_generator(batch_size, max_length, data_lines, shuffle=True):\n",
        "    index = 0\n",
        "    cur_batch = []\n",
        "    num_lines = len(data_lines)\n",
        "    lines_index = [*range(num_lines)]\n",
        "    if shuffle:\n",
        "        rnd.shuffle(lines_index)\n",
        "    while True:\n",
        "        if index >= num_lines:\n",
        "            index = 0\n",
        "            if shuffle:\n",
        "                rnd.shuffle(lines_index) \n",
        "        line = data_lines[lines_index[index]]\n",
        "        if len(line) < max_length:\n",
        "            cur_batch.append(line)\n",
        "        index += 1\n",
        "        if len(cur_batch) == batch_size:\n",
        "            batch = []\n",
        "            mask = []\n",
        "            for li in cur_batch:\n",
        "                tensor = line_to_tensor(li)\n",
        "                pad = [0] * (max_length - len(tensor))\n",
        "                tensor_pad = tensor + pad\n",
        "                batch.append(tensor_pad)\n",
        "                example_mask = [1]*len(tensor) + [0]*(max_length - len(tensor))\n",
        "                mask.append(example_mask)\n",
        "            batch_np_arr = np.array(batch)\n",
        "            mask_np_arr = np.array(mask)\n",
        "            yield batch_np_arr, batch_np_arr, mask_np_arr\n",
        "            cur_batch = []"
      ],
      "metadata": {
        "id": "5yAMP512IiUD"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def char_predict_model(vocab_size=256, d_model=512, gru_layers=2, mode=\"train\"):\n",
        "  return tl.Serial(\n",
        "      tl.ShiftRight(mode=mode),\n",
        "      tl.Embedding(vocab_size, d_model),\n",
        "      [tl.GRU(d_model) for _ in range(gru_layers)],\n",
        "      tl.Dense(d_model),\n",
        "      tl.LogSoftmax()\n",
        "  )"
      ],
      "metadata": {
        "id": "rrB6awVgJ9y1"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from trax.supervised import training\n",
        "\n",
        "def create_training_loop(model, train_stream, eval_stream, output_dir=\"/content/model/\"):\n",
        "  train_task = training.TrainTask(\n",
        "      labeled_data=train_stream,\n",
        "      loss_layer=tl.CrossEntropyLoss(),\n",
        "      optimizer=trax.optimizers.Adam(0.0005),\n",
        "      n_steps_per_checkpoint=10,\n",
        "  )\n",
        "  eval_task = training.EvalTask(\n",
        "      labeled_data=eval_stream, \n",
        "      metrics=[tl.CrossEntropyLoss(), tl.Accuracy()])\n",
        "  \n",
        "  loop = training.Loop(\n",
        "      model,\n",
        "      train_task, \n",
        "      eval_tasks=[eval_task], \n",
        "      output_dir=output_dir\n",
        "      )\n",
        "  return loop"
      ],
      "metadata": {
        "id": "9fO6ENW6N5HC"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "max_length = 64\n",
        "train_stream = data_generator(batch_size, max_length, train)\n",
        "eval_stream = data_generator(batch_size, max_length, eval)\n",
        "model = char_predict_model()"
      ],
      "metadata": {
        "id": "bt1-7ih-Pwt2"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/model/\n",
        "loop = create_training_loop(model, train_stream, eval_stream)\n",
        "loop.run(n_steps=300)"
      ],
      "metadata": {
        "id": "EWY_k-m8QhuU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gumbel_sample(log_probs, temperature=0.5):\n",
        "    \"\"\"Gumbel sampling from a categorical distribution.\"\"\"\n",
        "    u = np.random.uniform(low=1e-6, high=1.0 - 1e-6, size=log_probs.shape)\n",
        "    g = -np.log(-np.log(u))\n",
        "    return np.argmax(log_probs + g * temperature, axis=-1)\n",
        "\n",
        "def predict(num_chars, prefix):\n",
        "    inp = [ord(c) for c in prefix]\n",
        "    result = [c for c in prefix]\n",
        "    max_len = len(prefix) + num_chars\n",
        "    for _ in range(num_chars):\n",
        "        cur_inp = np.array(inp + [0] * (max_len - len(inp)))\n",
        "        outp = model(cur_inp[None, :])  # Add batch dim.\n",
        "        next_char = gumbel_sample(outp[0, len(inp)])\n",
        "        inp += [int(next_char)]\n",
        "       \n",
        "        if inp[-1] == 1:\n",
        "            break  # EOS\n",
        "        result.append(chr(int(next_char)))\n",
        "    \n",
        "    return \"\".join(result)"
      ],
      "metadata": {
        "id": "4zJxnjUZT0D8"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict(5, \"My n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "2OiemD0aWDqt",
        "outputId": "52187bc2-7647-4e88-dfec-672849ca252e"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'My nictee'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    }
  ]
}